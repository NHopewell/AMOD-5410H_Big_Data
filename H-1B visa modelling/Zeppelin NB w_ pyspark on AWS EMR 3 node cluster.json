{"paragraphs":[{"text":"%pyspark\n# notice spark session is attached by default since I ran this notebook right on spark.\nspark\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<pyspark.sql.session.SparkSession object at 0x7f64bbba1bd0>\n"}]},"apps":[],"jobName":"paragraph_1525194123621_1513817299","id":"20180429-153346_599160499","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:274"},{"text":"%md\nNEVER overwrite spark when running a zeppelin notebook- it assumes you'll be using spark. You should not define a spark session like you would in a Jupyter notebook\nYou want to use a sparksession not a sparkcontext because that is what the new spark data frames run off of\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>NEVER overwrite spark when running a zeppelin notebook- it assumes you'll be using spark. You should not define a spark session like you would in a Jupyter notebook\n<br  />You want to use a sparksession not a sparkcontext because that is what the new spark data frames run off of</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123627_1511893555","id":"20180429-194524_487668116","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:275"},{"text":"%md\nTo read in data which is hosted on s3 bucket, you need to pass in the keys (unless you allow public access like I have, see: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/) \nThis format is very good if you have a very large data set distributed. I will provide the read in layout for if I did not make the bucket public","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>To read in data which is hosted on s3 bucket, you need to pass in the keys (unless you allow public access like I have, see: https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/)\n<br  />This format is very good if you have a very large data set distributed. I will provide the read in layout for if I did not make the bucket public</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123627_1511893555","id":"20180429-194636_1900068495","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"%pyspark\n\n# df = spark.read.csv(\"s3n://Myaccesskey:secretaccesskey@bucketname/filename.csv\")\n\nnew_h1b_data = spark.read.csv(\"s3n://h1bdatabucket/updated_2017_data.csv\", inferSchema = True, header = True)\n\n# or you can use local file reading like I used in my last notebook running on an ec2 instance","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123627_1511893555","id":"20180429-153434_1863768200","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"text":"%pyspark\n# evaluation metrics\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator \nfrom pyspark.ml import Pipeline","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123628_1509969810","id":"20180429-154336_1450026260","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:278"},{"text":"%pyspark\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import (DecisionTreeClassifier, \n                                       RandomForestClassifier, \n                                       GBTClassifier)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123628_1509969810","id":"20180429-154337_856687967","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:279"},{"text":"%pyspark\nnew_h1b_data.printSchema()","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- CASE_STATUS: integer (nullable = true)\n |-- TOTAL_WORKERS: integer (nullable = true)\n |-- NEW_EMPLOYMENT: integer (nullable = true)\n |-- CONTINUED_EMPLOYMENT: integer (nullable = true)\n |-- CHANGE_PREVIOUS_EMPLOYMENT: integer (nullable = true)\n |-- NEW_CONCURRENT_EMPLOYMENT: integer (nullable = true)\n |-- CHANGE_EMPLOYER: integer (nullable = true)\n |-- AMENDED_PETITION: integer (nullable = true)\n |-- PREVAILING_WAGE: double (nullable = true)\n |-- WAGE_RATE_OF_PAY_FROM: double (nullable = true)\n |-- FULL_TIME_POSITION_N: integer (nullable = true)\n |-- FULL_TIME_POSITION_Y: integer (nullable = true)\n |-- PW_SOURCE_CBA: integer (nullable = true)\n |-- PW_SOURCE_DBA: integer (nullable = true)\n |-- PW_SOURCE_OES: integer (nullable = true)\n |-- PW_SOURCE_Other: integer (nullable = true)\n |-- PW_SOURCE_SCA: integer (nullable = true)\n |-- WAGE_RATE_OF_PAY_TO_N: integer (nullable = true)\n |-- WAGE_RATE_OF_PAY_TO_Y: integer (nullable = true)\n |-- H1B_DEPENDENT_N: integer (nullable = true)\n |-- H1B_DEPENDENT_Y: integer (nullable = true)\n |-- WILLFUL_VIOLATOR_N: integer (nullable = true)\n |-- WILLFUL_VIOLATOR_Y: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1525194123628_1509969810","id":"20180429-154337_1191611264","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:280"},{"text":"%pyspark\nnew_h1b_data.columns","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['CASE_STATUS', 'TOTAL_WORKERS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', 'CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT', 'CHANGE_EMPLOYER', 'AMENDED_PETITION', 'PREVAILING_WAGE', 'WAGE_RATE_OF_PAY_FROM', 'FULL_TIME_POSITION_N', 'FULL_TIME_POSITION_Y', 'PW_SOURCE_CBA', 'PW_SOURCE_DBA', 'PW_SOURCE_OES', 'PW_SOURCE_Other', 'PW_SOURCE_SCA', 'WAGE_RATE_OF_PAY_TO_N', 'WAGE_RATE_OF_PAY_TO_Y', 'H1B_DEPENDENT_N', 'H1B_DEPENDENT_Y', 'WILLFUL_VIOLATOR_N', 'WILLFUL_VIOLATOR_Y']\n"}]},"apps":[],"jobName":"paragraph_1525194123628_1509969810","id":"20180429-154337_1687886477","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:281"},{"text":"%pyspark\nnew_h1b_data.head(1)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[Row(CASE_STATUS=1, TOTAL_WORKERS=1, NEW_EMPLOYMENT=1, CONTINUED_EMPLOYMENT=0, CHANGE_PREVIOUS_EMPLOYMENT=0, NEW_CONCURRENT_EMPLOYMENT=0, CHANGE_EMPLOYER=0, AMENDED_PETITION=0, PREVAILING_WAGE=59197.0, WAGE_RATE_OF_PAY_FROM=65811.0, FULL_TIME_POSITION_N=0, FULL_TIME_POSITION_Y=1, PW_SOURCE_CBA=0, PW_SOURCE_DBA=0, PW_SOURCE_OES=1, PW_SOURCE_Other=0, PW_SOURCE_SCA=0, WAGE_RATE_OF_PAY_TO_N=0, WAGE_RATE_OF_PAY_TO_Y=1, H1B_DEPENDENT_N=1, H1B_DEPENDENT_Y=0, WILLFUL_VIOLATOR_N=1, WILLFUL_VIOLATOR_Y=0)]\n"}]},"apps":[],"jobName":"paragraph_1525194123629_1509585061","id":"20180429-154338_1647184077","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:282"},{"text":"%pyspark\nfrom pyspark.ml.feature import VectorAssembler","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123629_1509585061","id":"20180429-165010_359114585","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:283"},{"text":"%pyspark\n# call VecAssem and initialize in and out\nvec_assem = VectorAssembler(inputCols = ['TOTAL_WORKERS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', \n                                         'CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT', 'CHANGE_EMPLOYER', \n                                         'AMENDED_PETITION', 'PREVAILING_WAGE', 'WAGE_RATE_OF_PAY_FROM', 'FULL_TIME_POSITION_N', \n                                         'FULL_TIME_POSITION_Y', 'PW_SOURCE_CBA', 'PW_SOURCE_DBA', 'PW_SOURCE_OES', 'PW_SOURCE_Other', \n                                         'PW_SOURCE_SCA', 'WAGE_RATE_OF_PAY_TO_N', 'WAGE_RATE_OF_PAY_TO_Y', 'H1B_DEPENDENT_N', \n                                         'H1B_DEPENDENT_Y', 'WILLFUL_VIOLATOR_N', 'WILLFUL_VIOLATOR_Y'], outputCol = 'Features')","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123629_1509585061","id":"20180429-165120_786330670","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:284"},{"text":"%pyspark\n# call vec_assem\ntransformed_data = vec_assem.transform(new_h1b_data)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123630_1510739308","id":"20180429-165125_257608123","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:285"},{"text":"%pyspark\n# MLlib ready data\nh1b_data = transformed_data.select('Features', 'CASE_STATUS')\n# train test split\ntrain_data,test_data = h1b_data.randomSplit([0.8, 0.2]) ","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123630_1510739308","id":"20180429-175734_1917085490","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:286"},{"text":"%md\nSo what does the data now look like before it is fed into an MLlib function?","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>So what does the data now look like before it is fed into an MLlib function?</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123630_1510739308","id":"20180429-185953_977273924","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:287"},{"text":"%pyspark\nh1b_data.show()","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-----------+\n|            Features|CASE_STATUS|\n+--------------------+-----------+\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,5,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,1,7,8,10,1...|          1|\n|(22,[0,2,7,8,10,1...|          1|\n|(22,[0,2,7,8,10,1...|          1|\n|(22,[0,2,7,8,10,1...|          1|\n|(22,[0,1,7,8,9,14...|          1|\n+--------------------+-----------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525194123631_1510354559","id":"20180429-185924_1853389183","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:288"},{"text":"%md\nNotice how each element of the features column is an array of the original values of each column from the visa data.","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Notice how each element of the features column is an array of the original values of each column from the visa data.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123631_1510354559","id":"20180429-190020_2086513248","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:289"},{"text":"%pyspark\n# decision tree, rand forest, g boosted\ndtc = DecisionTreeClassifier(labelCol='CASE_STATUS', featuresCol='Features')\nrfc = RandomForestClassifier(numTrees = 200, labelCol='CASE_STATUS', featuresCol='Features')\ngbt = GBTClassifier(labelCol='CASE_STATUS', featuresCol='Features')","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123631_1510354559","id":"20180429-175735_367110780","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:290"},{"text":"%pyspark\n# fit to training data\ndecision_tree = dtc.fit(train_data)\nrandom_forest = rfc.fit(train_data)\nboosted_tree = gbt.fit(train_data)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123632_1520742779","id":"20180429-175735_2095546","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:291"},{"text":"%pyspark\n# apply to test\ndtc_preds = decision_tree.transform(test_data)\nrfc_preds = random_forest.transform(test_data)\ngbt_preds = boosted_tree.transform(test_data)\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123632_1520742779","id":"20180429-175735_702954659","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:292"},{"text":"%pyspark\nbinary_eval = (labelCol = 'CASE_STATUS')","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123632_1520742779","id":"20180429-175736_692253281","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:293"},{"text":"%pyspark\nprint('Decision Tree fit:')\nprint(binary_eval.evaluate(dtc_preds))","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Decision Tree fit:\n0.616967154658\n"}]},"apps":[],"jobName":"paragraph_1525194123633_1520358031","id":"20180429-175736_2023209358","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:294"},{"text":"%pyspark\nprint('Random Forest fit:')\nprint(binary_eval.evaluate(rfc_preds))","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Random Forest fit:\n0.716950872169\n"}]},"apps":[],"jobName":"paragraph_1525194123633_1520358031","id":"20180429-175735_210879342","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:295"},{"text":"%pyspark\ngbt_preds.printSchema()","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Features: vector (nullable = true)\n |-- CASE_STATUS: integer (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = false)\n\n"}]},"apps":[],"jobName":"paragraph_1525194123633_1520358031","id":"20180429-181046_65415744","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:296"},{"text":"%pyspark\nprint('Boosted-Tree fit:')\nprint(binary_eval.evaluate(gbt_preds))","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Boosted-Tree fit:\n0.717922232626\n"}]},"apps":[],"jobName":"paragraph_1525194123634_1521512277","id":"20180429-175735_880139098","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:297"},{"text":"%md\n\nThis is the model performance without adjusting parameters. Simply using the default parameter values.   \n\nThis may not be good for any one particular data set.\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>This is the model performance without adjusting parameters. Simply using the default parameter values.</p>\n<p>This may not be good for any one particular data set.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123634_1521512277","id":"20180429-180559_1372213669","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:298"},{"text":"%pyspark\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Select (prediction, true label) and compute test error\naccuracy  = MulticlassClassificationEvaluator(labelCol = 'CASE_STATUS', metricName=\"accuracy\")\nprecision  = MulticlassClassificationEvaluator(labelCol = 'CASE_STATUS', metricName=\"weightedPrecision\")\nrecall  = MulticlassClassificationEvaluator(labelCol = 'CASE_STATUS', metricName=\"weightedRecall\")","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123634_1521512277","id":"20180429-180600_166916044","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:299"},{"text":"%pyspark\n# metrics for the decision tree\ndtc_acc = accuracy.evaluate(dtc_preds)\ndtc_prec = precision.evaluate(dtc_preds)\ndtc_rec = recall.evaluate(dtc_preds)\n# metris for random forest\nrfc_acc = accuracy.evaluate(rfc_preds)\nrfc_prec = precision.evaluate(rfc_preds)\nrfc_rec = recall.evaluate(rfc_preds)\n# metrics for gradient boosted trees\ngbt_acc = accuracy.evaluate(gbt_preds)\ngbt_prec = precision.evaluate(gbt_preds)\ngbt_rec = recall.evaluate(gbt_preds)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525194123634_1521127528","id":"20180429-180600_2122235074","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:300"},{"text":"%pyspark\nprint('Decision tree accurary: {0:2.2f}%'.format(dtc_acc*100))\nprint('Decision tree Precision: {0:2.2f}%'.format(dtc_prec*100))\nprint('Decision tree Recall: {0:2.2f}%'.format(dtc_rec*100))\nprint('-'*60)\nprint('200 Random forest accuracy: {0:2.2f}%'.format(rfc_acc*100))\nprint('200 Random forest precision: {0:2.2f}%'.format(rfc_prec*100))\nprint('200 Random forest recall: {0:2.2f}%'.format(rfc_rec*100))\nprint('-'*60)\nprint('Boosted tree ensemble accuracy: {0:2.2f}%'.format(gbt_acc*100))\nprint('Boosted tree ensemble precision: {0:2.2f}%'.format(gbt_prec*100))\nprint('Boosted tree ensemble recall: {0:2.2f}%'.format(gbt_rec*100))","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Decision tree accurary: 98.73%\nDecision tree Precision: 98.24%\nDecision tree Recall: 98.73%\n------------------------------------------------------------\n200 Random forest accuracy: 98.76%\n200 Random forest precision: 97.55%\n200 Random forest recall: 98.76%\n------------------------------------------------------------\nBoosted tree ensemble accuracy: 98.74%\nBoosted tree ensemble precision: 98.47%\nBoosted tree ensemble recall: 98.74%\n"}]},"apps":[],"jobName":"paragraph_1525194123635_1521127528","id":"20180429-180601_2102260015","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:301"},{"text":"%md\n### What about predicitive power? \n\nIt seems these models have fit the data very well. It is concerning when a simply decision tree fits so well. It tells me the data was very easily seperable.  \nMy first thought it that some variables had incredibly strong predicitive power and resulted in very, very pure splits.   \n\nI can see the predictive power of each feauture to get an idea of this.   \nI can do this by looking at feature importance. This will return a sparce vector where the first element is the number of feartures used and the second element is a dictionary including an index of the features (so the first feature would be index 0) followed by the feature importance. \n\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>What about predicitive power?</h3>\n<p>It seems these models have fit the data very well. It is concerning when a simply decision tree fits so well. It tells me the data was very easily seperable.\n<br  />My first thought it that some variables had incredibly strong predicitive power and resulted in very, very pure splits.</p>\n<p>I can see the predictive power of each feauture to get an idea of this.\n<br  />I can do this by looking at feature importance. This will return a sparce vector where the first element is the number of feartures used and the second element is a dictionary including an index of the features (so the first feature would be index 0) followed by the feature importance.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123635_1521127528","id":"20180429-180600_836702883","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:302"},{"text":"%pyspark\ndecision_tree.featureImportances","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SparseVector(22, {0: 0.0214, 1: 0.0105, 2: 0.008, 3: 0.0406, 4: 0.0046, 7: 0.1585, 8: 0.3133, 9: 0.1055, 11: 0.0237, 13: 0.1203, 14: 0.0427, 16: 0.0616, 18: 0.0893})\n"}]},"apps":[],"jobName":"paragraph_1525194123635_1521127528","id":"20180429-180600_1305790680","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:303"},{"text":"%md \n\nFor the decision tree, feature at index 8 was very important. Features at indexes 7, 9 and 13  were also important (and to a lesser extend, feature 18)\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>For the decision tree, feature at index 8 was very important. Features at indexes 7, 9 and 13  were also important (and to a lesser extend, feature 18)</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123636_1519203784","id":"20180429-190734_983259497","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:304"},{"text":"%pyspark\nrandom_forest.featureImportances\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SparseVector(22, {0: 0.0316, 1: 0.0235, 2: 0.0147, 3: 0.029, 4: 0.0098, 5: 0.019, 6: 0.0092, 7: 0.0847, 8: 0.2236, 9: 0.0347, 10: 0.0295, 11: 0.0348, 12: 0.0843, 13: 0.0914, 14: 0.0604, 16: 0.0318, 17: 0.0229, 18: 0.0775, 19: 0.0832, 20: 0.0022, 21: 0.0021})\n"}]},"apps":[],"jobName":"paragraph_1525194123636_1519203784","id":"20180429-180600_51566011","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:305"},{"text":"%md\nFor the random forest, features at index 7, 8, 12, 13, 18, and 19 were important. (especially index 8)","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>For the random forest, features at index 7, 8, 12, 13, 18, and 19 were important. (especially index 8)</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123636_1519203784","id":"20180429-190846_1493059750","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:306"},{"text":"%pyspark\nboosted_tree.featureImportances","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SparseVector(22, {0: 0.0505, 1: 0.1036, 2: 0.0176, 3: 0.0174, 4: 0.0031, 5: 0.0154, 6: 0.0232, 7: 0.242, 8: 0.2237, 9: 0.0267, 10: 0.0194, 11: 0.0115, 12: 0.0097, 13: 0.0575, 14: 0.0324, 15: 0.0248, 16: 0.0293, 17: 0.0181, 18: 0.041, 19: 0.0284, 20: 0.0008, 21: 0.004})\n"}]},"apps":[],"jobName":"paragraph_1525194123637_1518819035","id":"20180429-180600_602891170","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:307"},{"text":"%md\nFor the gradient-boosted ensemble, features 1, 7, 8, and to a lesser extend, 13 and 0 were important. \n\nRight away, feature at index 8 seems very important. \n\nI will list the columns again below and start index 0 after 'CASE_STATUS' which was not used as a feature but was the label column.\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>For the gradient-boosted ensemble, features 1, 7, 8, and to a lesser extend, 13 and 0 were important.</p>\n<p>Right away, feature at index 8 seems very important.</p>\n<p>I will list the columns again below and start index 0 after 'CASE_STATUS' which was not used as a feature but was the label column.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123637_1518819035","id":"20180429-191130_721220655","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:308"},{"text":"%pyspark\nnew_h1b_data.columns","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"python","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['CASE_STATUS', 'TOTAL_WORKERS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', 'CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT', 'CHANGE_EMPLOYER', 'AMENDED_PETITION', 'PREVAILING_WAGE', 'WAGE_RATE_OF_PAY_FROM', 'FULL_TIME_POSITION_N', 'FULL_TIME_POSITION_Y', 'PW_SOURCE_CBA', 'PW_SOURCE_DBA', 'PW_SOURCE_OES', 'PW_SOURCE_Other', 'PW_SOURCE_SCA', 'WAGE_RATE_OF_PAY_TO_N', 'WAGE_RATE_OF_PAY_TO_Y', 'H1B_DEPENDENT_N', 'H1B_DEPENDENT_Y', 'WILLFUL_VIOLATOR_N', 'WILLFUL_VIOLATOR_Y']\n"}]},"apps":[],"jobName":"paragraph_1525194123637_1518819035","id":"20180429-191550_415526628","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:309"},{"text":"%md\n'WAGE_RATE_OF_PAY_FROM' is the column with the most predictive power across the board. Recall from the data dictionary that this column contains information about the employer’s proposed wage rate.  \nIt seems this information is a very big indicator of whether or not an individuals visa will be certifed or denied. \n\n'PREVAILING_WAGE' and 'PW_SOURCE_OES' were also important across the board. \n\n'PREVAILING_WAGE' refers to the prevailing Wage for the job being requested for temporary labor condition.  \n'PW_SOURCE_OES' refers to wages being calculated bt  The Occupational Employment Statistics (OES) program which produces employment and wage estimates annually for over 800 occupations. I have a feeling that most wages were calculated in this way and that is the simple reason why it is important. There may be another answer, I would have to know more about the US visa process to fully appreciate this. \n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>'WAGE_RATE_OF_PAY_FROM' is the column with the most predictive power across the board. Recall from the data dictionary that this column contains information about the employer’s proposed wage rate.\n<br  />It seems this information is a very big indicator of whether or not an individuals visa will be certifed or denied.</p>\n<p>'PREVAILING_WAGE' and 'PW_SOURCE_OES' were also important across the board.</p>\n<p>'PREVAILING_WAGE' refers to the prevailing Wage for the job being requested for temporary labor condition.\n<br  />'PW_SOURCE_OES' refers to wages being calculated bt  The Occupational Employment Statistics (OES) program which produces employment and wage estimates annually for over 800 occupations. I have a feeling that most wages were calculated in this way and that is the simple reason why it is important. There may be another answer, I would have to know more about the US visa process to fully appreciate this.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123638_1519973282","id":"20180429-191550_2047378887","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:310"},{"text":"%md\nAnother important thing to notice is that both the continuous variables were important. With one being very important. I will need to research whether this is an artifact of how continuous and binary variables behave in the splitting process. That being said, it is more likely that wages are simply the most important factor. Individuals with high-paying, in-demand jobs ought to be more likely to be approved. In fact, the h1B specificially is to bring skilled immigrants into the US who fit into specialty occupations. The regulations define a \"specialty occupation\" as requiring theoretical and practical application of a body of highly specialized knowledge in a field of human endeavor. It makes sense that the more specialized individuals, who would earn more, would be approved. ","dateUpdated":"2018-05-01T17:02:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Another important thing to notice is that both the continuous variables were important. With one being very important. I will need to research whether this is an artifact of how continuous and binary variables behave in the splitting process. That being said, it is more likely that wages are simply the most important factor. Individuals with high-paying, in-demand jobs ought to be more likely to be approved. In fact, the h1B specificially is to bring skilled immigrants into the US who fit into specialty occupations. The regulations define a &ldquo;specialty occupation&rdquo; as requiring theoretical and practical application of a body of highly specialized knowledge in a field of human endeavor. It makes sense that the more specialized individuals, who would earn more, would be approved.</p>\n"}]},"apps":[],"jobName":"paragraph_1525194123638_1519973282","id":"20180429-191549_181111440","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:311"},{"text":"%md\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525194123638_1519973282","id":"20180429-193319_467545620","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:312"},{"text":"%md\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525194123639_1519588533","id":"20180429-193319_710803441","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:313"},{"text":"%md\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525194123639_1519588533","id":"20180429-193318_451947163","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:314"},{"text":"%pyspark\n","dateUpdated":"2018-05-01T17:02:03+0000","config":{"colWidth":12,"results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525194123641_1517280039","id":"20180429-165131_755617784","dateCreated":"2018-05-01T17:02:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:319"}],"name":"Zeppelin NB w/ pyspark on AWS EMR 3 node cluster","id":"2DEBP7HSZ","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}